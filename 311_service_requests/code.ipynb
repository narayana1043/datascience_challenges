{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spark session and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import functions\n",
    "from pyspark.sql.functions import col, udf\n",
    "from IPython.display import display\n",
    "from datetime import datetime\n",
    "from pyspark.sql.types import FloatType, BooleanType, IntegerType\n",
    "from time import mktime\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "spark_conf = SparkConf() \\\n",
    "    .setAll([\n",
    "         ['spark.serializer','org.apache.spark.serializer.KryoSerializer'],\n",
    "         ['spark.rdd.compress','true'],   \n",
    "    ])\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"pager\") \\\n",
    "    .config(conf=spark_conf) \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create dataframe and drop low level features\n",
    "save the processed file as parquet since it is a columnar format we can perfrom groupby operations faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read 311_service_requests data from hdfs\n",
    "df = spark.read.csv('hdfs://ip-172-31-51-46.ec2.internal/pager/311_service_requests.csv', header=True,\n",
    "                   inferSchema=True, ignoreLeadingWhiteSpace=None, ignoreTrailingWhiteSpace=None)\n",
    "\n",
    "# rename columns and convert to lower case\n",
    "for col, dtype in df.dtypes:\n",
    "    new_col = col.replace(\" \", \"\")\n",
    "    df = df.withColumnRenamed(col, new_col)\n",
    "    if dtype == 'string':\n",
    "        df = df.withColumn(new_col, functions.lower(df[new_col]))\n",
    "\n",
    "\n",
    "\n",
    "df = df.dropna(how='any', subset=['CreatedDate','ClosedDate'])\n",
    "\n",
    "# UDF fuctions\n",
    "get_month_func = udf(lambda x: datetime.strptime(x, '%m/%d/%Y %I:%M:%S %p').month, IntegerType())\n",
    "get_year_func = udf(lambda x: datetime.strptime(x, '%m/%d/%Y %I:%M:%S %p').year, IntegerType())\n",
    "time_difference_func = udf(lambda x, y: (datetime.strptime(x, '%m/%d/%Y %I:%M:%S %p') - \n",
    "                                         datetime.strptime(y, '%m/%d/%Y %I:%M:%S %p')).total_seconds()/3600, \n",
    "                           FloatType())\n",
    "is_school_func = udf(lambda x: True if x == \"Unspecified\" else False, BooleanType())\n",
    "\n",
    "\n",
    "# create new columns and select required columns\n",
    "df = df.withColumn('Month', get_month_func(df['CreatedDate']))\n",
    "df = df.withColumn('Year', get_year_func(df['CreatedDate']))\n",
    "df = df.withColumn('TimeTaken', time_difference_func(df['ClosedDate'], df['CreatedDate']))\n",
    "df = df.withColumn('SchoolZone', is_school_func(df['SchoolName']))\n",
    "\n",
    "# filters\n",
    "df.filter(df['TimeTaken']>0)\n",
    "df = df[['UniqueKey', 'Month', 'Year', 'TimeTaken', 'Agency', 'ComplaintType', 'Descriptor', 'LocationType',\n",
    "         'Incidentzip', 'AddressType', 'City', 'FacilityType', 'Borough', 'Status', 'SchoolZone', 'CreatedDate',\n",
    "         'ClosedDate']]\n",
    "\n",
    "df.write.parquet('hdfs://ip-172-31-51-46.ec2.internal/pager/parquet/311_data', mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis\n",
    "\n",
    " Group based on the each of the selected column for selected column + Time Taken column pair\n",
    " \n",
    " For each grouping use aggregate for count and mean\n",
    " \n",
    " Convert the grouped data into pandas dataframes and write into excel sheets\n",
    " \n",
    " Perfrom exploratory analysis means of grouped data by joining all the pandas dataframes formed\n",
    " \n",
    " Check for variance in the means\n",
    " \n",
    "  (i) Large variance/stddev implies that the feature is important driver because it means that in each \n",
    "      feature the category are diverse and have extreme varying effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"hdfs://ip-172-31-51-46.ec2.internal/pager/parquet/311_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimeTaken</th>\n",
       "      <th>Agency</th>\n",
       "      <th>ComplaintType</th>\n",
       "      <th>LocationType</th>\n",
       "      <th>AddressType</th>\n",
       "      <th>City</th>\n",
       "      <th>FacilityType</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Status</th>\n",
       "      <th>SchoolZone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>2.900000e+01</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2282.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>-2.408990e+05</td>\n",
       "      <td>-30254.601041</td>\n",
       "      <td>-65967.413321</td>\n",
       "      <td>-62.621543</td>\n",
       "      <td>87.751361</td>\n",
       "      <td>-119119.589022</td>\n",
       "      <td>295.882093</td>\n",
       "      <td>-180390.380575</td>\n",
       "      <td>-46.657091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>std</td>\n",
       "      <td>4.341196e+05</td>\n",
       "      <td>151318.642783</td>\n",
       "      <td>239170.313188</td>\n",
       "      <td>364.725634</td>\n",
       "      <td>14132.847890</td>\n",
       "      <td>293709.568884</td>\n",
       "      <td>693.739331</td>\n",
       "      <td>372479.377116</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>-1.028939e+06</td>\n",
       "      <td>-986899.875000</td>\n",
       "      <td>-977421.773707</td>\n",
       "      <td>-754.161199</td>\n",
       "      <td>-645431.919074</td>\n",
       "      <td>-718644.858181</td>\n",
       "      <td>-271.246716</td>\n",
       "      <td>-991193.293689</td>\n",
       "      <td>-46.657091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25%</td>\n",
       "      <td>-1.478868e+04</td>\n",
       "      <td>3.187477</td>\n",
       "      <td>4.335747</td>\n",
       "      <td>-90.911113</td>\n",
       "      <td>316.186239</td>\n",
       "      <td>-43.495131</td>\n",
       "      <td>64.766670</td>\n",
       "      <td>-3271.359866</td>\n",
       "      <td>-46.657091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50%</td>\n",
       "      <td>8.517787e+01</td>\n",
       "      <td>126.508135</td>\n",
       "      <td>183.532326</td>\n",
       "      <td>38.834693</td>\n",
       "      <td>371.210968</td>\n",
       "      <td>-7.003123</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>32.418155</td>\n",
       "      <td>-46.657091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>75%</td>\n",
       "      <td>3.077275e+02</td>\n",
       "      <td>471.247654</td>\n",
       "      <td>631.201495</td>\n",
       "      <td>160.169901</td>\n",
       "      <td>387.588823</td>\n",
       "      <td>311.472515</td>\n",
       "      <td>235.449997</td>\n",
       "      <td>180.691970</td>\n",
       "      <td>-46.657091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max</td>\n",
       "      <td>1.539200e+03</td>\n",
       "      <td>16222.077081</td>\n",
       "      <td>2198.201251</td>\n",
       "      <td>234.307302</td>\n",
       "      <td>8398.497027</td>\n",
       "      <td>3579.358369</td>\n",
       "      <td>8135.866699</td>\n",
       "      <td>6093.748832</td>\n",
       "      <td>-46.657091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TimeTaken        Agency  ComplaintType   LocationType  AddressType  \\\n",
       "0     count  2.900000e+01     281.000000     153.000000     6.000000   \n",
       "1      mean -2.408990e+05  -30254.601041  -65967.413321   -62.621543   \n",
       "2       std  4.341196e+05  151318.642783  239170.313188   364.725634   \n",
       "3       min -1.028939e+06 -986899.875000 -977421.773707  -754.161199   \n",
       "4       25% -1.478868e+04       3.187477       4.335747   -90.911113   \n",
       "5       50%  8.517787e+01     126.508135     183.532326    38.834693   \n",
       "6       75%  3.077275e+02     471.247654     631.201495   160.169901   \n",
       "7       max  1.539200e+03   16222.077081    2198.201251   234.307302   \n",
       "\n",
       "            City   FacilityType      Borough         Status  SchoolZone  \n",
       "0    2282.000000       6.000000   549.000000      22.000000    1.000000  \n",
       "1      87.751361 -119119.589022   295.882093 -180390.380575  -46.657091  \n",
       "2   14132.847890  293709.568884   693.739331  372479.377116         NaN  \n",
       "3 -645431.919074 -718644.858181  -271.246716 -991193.293689  -46.657091  \n",
       "4     316.186239     -43.495131    64.766670   -3271.359866  -46.657091  \n",
       "5     371.210968      -7.003123   124.000000      32.418155  -46.657091  \n",
       "6     387.588823     311.472515   235.449997     180.691970  -46.657091  \n",
       "7    8398.497027    3579.358369  8135.866699    6093.748832  -46.657091  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grouped_counts_dict = {}\n",
    "pandas_df_dict = {}\n",
    "\n",
    "select_columns = ['Agency', 'ComplaintType', 'LocationType', 'AddressType', 'City', 'FacilityType', 'Borough', \n",
    "                  'Status', 'SchoolZone']\n",
    "\n",
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter('./pager_analysis.xlsx', engine='xlsxwriter')\n",
    "\n",
    "for col in select_columns:\n",
    "    group = [col] + ['TimeTaken']\n",
    "    grouped = df.select(group).groupBy(col)\n",
    "    grouped_counts_dict[col] = {}\n",
    "    grouped_counts_dict[col]['counts'] = grouped.count()\n",
    "    grouped_counts_dict[col]['mean_time_taken'] = grouped.mean('TimeTaken')\n",
    "\n",
    "    pandas_df_count = grouped_counts_dict[col]['counts'].toPandas()\n",
    "    pandas_df_mean = grouped_counts_dict[col]['mean_time_taken'].toPandas()\n",
    "    \n",
    "    pandas_df = pandas_df_count.join(pandas_df_mean.set_index(col), on=col)\n",
    "    pandas_df_dict[col] = pandas_df[['avg(TimeTaken)']].describe()\n",
    "    \n",
    "    pandas_df.to_excel(writer, sheet_name=col)\n",
    "\n",
    "exploratory_analysis = pd.concat([pandas_df_dict[col] for col in select_columns], axis=1).reset_index()\n",
    "exploratory_analysis.columns = ['TimeTaken'] + select_columns\n",
    "exploratory_analysis.to_excel(writer, sheet_name='exploratory_analysis')\n",
    "\n",
    "display(exploratory_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the top features change over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group based on Year/Month and the column\n",
    "\n",
    "Aggregate on the TimeTaken column (mean, counts)\n",
    "\n",
    "convert the result into pandas dataframe and write to xlsx file\n",
    "\n",
    "use the excel file to check if the mean is changing with year/month (time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter('./pager_yearly_analysis.xlsx', engine='xlsxwriter')\n",
    "\n",
    "for col in select_columns:\n",
    "    group = [col] + ['TimeTaken', 'Year']\n",
    "    grouped = df.select(group).groupBy(['Year'] + [col])\n",
    "    grouped_counts_dict[col] = {}\n",
    "    grouped_counts_dict[col]['counts'] = grouped.count()\n",
    "    grouped_counts_dict[col]['mean_time_taken'] = grouped.mean('TimeTaken')\n",
    "\n",
    "    pandas_df_count = grouped_counts_dict[col]['counts'].toPandas()\n",
    "    pandas_df_mean = grouped_counts_dict[col]['mean_time_taken'].toPandas()\n",
    "    \n",
    "    pandas_df = pandas_df_count.join(pandas_df_mean.set_index(['Year'] + [col]), \n",
    "                                     on=['Year'] + [col]).sort_values(by=col).reset_index(drop=True)\n",
    "    pandas_df.to_excel(writer, sheet_name=col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter('./pager_monthly_analysis.xlsx', engine='xlsxwriter')\n",
    "\n",
    "for col in select_columns:\n",
    "    group = [col] + ['TimeTaken', 'Month']\n",
    "    grouped = df.select(group).groupBy(['Month'] + [col])\n",
    "    grouped_counts_dict[col] = {}\n",
    "    grouped_counts_dict[col]['counts'] = grouped.count()\n",
    "    grouped_counts_dict[col]['mean_time_taken'] = grouped.mean('TimeTaken')\n",
    "\n",
    "    pandas_df_count = grouped_counts_dict[col]['counts'].toPandas()\n",
    "    pandas_df_mean = grouped_counts_dict[col]['mean_time_taken'].toPandas()\n",
    "    \n",
    "    pandas_df = pandas_df_count.join(pandas_df_mean.set_index(['Month'] + [col]), \n",
    "                                     on=['Month'] + [col]).sort_values(by=col).reset_index(drop=True)\n",
    "    pandas_df.to_excel(writer, sheet_name=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
